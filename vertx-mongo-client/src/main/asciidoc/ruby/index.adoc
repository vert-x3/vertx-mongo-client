= Vert.x MongoDB Client

A Vert.x client allowing applications to interact with a MongoDB instance, whether that's
saving, retrieving, searching, or deleting documents.

Mongo is a great match for persisting data in a Vert.x application
as it natively handles JSON (BSON) documents.

*Features*

* Completely non-blocking
* Custom codec to support fast serialization to/from Vert.x JSON
* Supports a majority of the configuration options from the MongoDB Java Driver

This client is based on the
http://mongodb.github.io/mongo-java-driver/3.2/driver-async/getting-started[MongoDB Async Driver].

== Using Vert.x MongoDB Client

To use this project, add the following dependency to the _dependencies_ section of your build descriptor:

* Maven (in your `pom.xml`):

[source,xml,subs="+attributes"]
----
<dependency>
  <groupId>io.vertx</groupId>
  <artifactId>vertx-mongo-client</artifactId>
  <version>3.5.0</version>
</dependency>
----

* Gradle (in your `build.gradle` file):

[source,groovy,subs="+attributes"]
----
compile 'io.vertx:vertx-mongo-client:3.5.0'
----


== Creating a client

You can create a client in several ways:

=== Using the default shared pool

In most cases you will want to share a pool between different client instances.

E.g. you scale your application by deploying multiple instances of your verticle and you want each verticle instance
to share the same pool so you don't end up with multiple pools

The simplest way to do this is as follows:

[source,ruby]
----
require 'vertx-mongo/mongo_client'

client = VertxMongo::MongoClient.create_shared(vertx, config)


----

The first call to `link:../../yardoc/VertxMongo/MongoClient.html#create_shared-class_method[MongoClient.createShared]`
will actually create the pool, and the specified config will be used.

Subsequent calls will return a new client instance that uses the same pool, so the configuration won't be used.

=== Specifying a pool source name

You can create a client specifying a pool source name as follows

[source,ruby]
----
require 'vertx-mongo/mongo_client'

client = VertxMongo::MongoClient.create_shared(vertx, config, "MyPoolName")


----

If different clients are created using the same Vert.x instance and specifying the same pool name, they will
share the same pool.

The first call to `link:../../yardoc/VertxMongo/MongoClient.html#create_shared-class_method[MongoClient.createShared]`
will actually create the pool, and the specified config will be used.

Subsequent calls will return a new client instance that uses the same pool, so the configuration won't be used.

Use this way of creating if you wish different groups of clients to have different pools, e.g. they're
interacting with different databases.

=== Creating a client with a non shared data pool

In most cases you will want to share a pool between different client instances.
However, it's possible you want to create a client instance that doesn't share its pool with any other client.

In that case you can use `link:../../yardoc/VertxMongo/MongoClient.html#create_non_shared-class_method[MongoClient.createNonShared]`.

[source,ruby]
----
require 'vertx-mongo/mongo_client'

client = VertxMongo::MongoClient.create_non_shared(vertx, config)


----

This is equivalent to calling `link:../../yardoc/VertxMongo/MongoClient.html#create_shared-class_method[MongoClient.createShared]`
with a unique pool name each time.


== Using the API

The client API is represented by `link:../../yardoc/VertxMongo/MongoClient.html[MongoClient]`.

=== Saving documents

To save a document you use `link:../../yardoc/VertxMongo/MongoClient.html#save-instance_method[save]`.

If the document has no `\_id` field, it is inserted, otherwise, it is _upserted_. Upserted means it is inserted
if it doesn't already exist, otherwise it is updated.

If the document is inserted and has no id, then the id field generated will be returned to the result handler.

Here's an example of saving a document and getting the id back

[source,ruby]
----

# Document has no id

document = {
  'title' => "The Hobbit"
}

mongoClient.save("books", document) { |res_err,res|

  if (res_err == nil)

    id = res
    puts "Saved book with id #{id}"

  else
    res_err.print_stack_trace()
  end

}


----

And here's an example of saving a document which already has an id.

[source,ruby]
----

# Document has an id already

document = {
  'title' => "The Hobbit",
  '_id' => "123244"
}

mongoClient.save("books", document) { |res_err,res|

  if (res_err == nil)

    # ...

  else
    res_err.print_stack_trace()
  end

}


----

=== Inserting documents

To insert a document you use `link:../../yardoc/VertxMongo/MongoClient.html#insert-instance_method[insert]`.

If the document is inserted and has no id, then the id field generated will be returned to the result handler.

[source,ruby]
----

# Document has an id already

document = {
  'title' => "The Hobbit"
}

mongoClient.insert("books", document) { |res_err,res|

  if (res_err == nil)

    id = res
    puts "Inserted book with id #{id}"

  else
    res_err.print_stack_trace()
  end

}


----

If a document is inserted with an id, and a document with that id already eists, the insert will fail:

[source,ruby]
----

# Document has an id already

document = {
  'title' => "The Hobbit",
  '_id' => "123244"
}

mongoClient.insert("books", document) { |res_err,res|

  if (res_err == nil)

    #...

  else

    # Will fail if the book with that id already exists.
  end

}


----

=== Updating documents

To update a documents you use `link:../../yardoc/VertxMongo/MongoClient.html#update-instance_method[update]`.

This updates one or multiple documents in a collection. The json object that is passed in the `update`
parameter must contain http://docs.mongodb.org/manual/reference/operator/update-field/[Update Operators] and determines
how the object is updated.

The json object specified in the query parameter determines which documents in the collection will be updated.

Here's an example of updating a document in the books collection:

[source,ruby]
----

# Match any documents with title=The Hobbit
query = {
  'title' => "The Hobbit"
}

# Set the author field
update = {
  '$set' => {
    'author' => "J. R. R. Tolkien"
  }
}

mongoClient.update("books", query, update) { |res_err,res|

  if (res_err == nil)

    puts "Book updated !"

  else

    res_err.print_stack_trace()
  end

}


----

To specify if the update should upsert or update multiple documents, use `link:../../yardoc/VertxMongo/MongoClient.html#update_with_options-instance_method[updateWithOptions]`
and pass in an instance of `link:../dataobjects.html#UpdateOptions[UpdateOptions]`.

This has the following fields:

`multi`:: set to true to update multiple documents
`upsert`:: set to true to insert the document if the query doesn't match
`writeConcern`:: the write concern for this operation

[source,ruby]
----

# Match any documents with title=The Hobbit
query = {
  'title' => "The Hobbit"
}

# Set the author field
update = {
  '$set' => {
    'author' => "J. R. R. Tolkien"
  }
}

options = {
  'multi' => true
}

mongoClient.update_with_options("books", query, update, options) { |res_err,res|

  if (res_err == nil)

    puts "Book updated !"

  else

    res_err.print_stack_trace()
  end

}


----

=== Replacing documents

To replace documents you use `link:../../yardoc/VertxMongo/MongoClient.html#replace-instance_method[replace]`.

This is similar to the update operation, however it does not take any update operators like `update`.
Instead it replaces the entire document with the one provided.

Here's an example of replacing a document in the books collection

[source,ruby]
----

query = {
  'title' => "The Hobbit"
}

replace = {
  'title' => "The Lord of the Rings",
  'author' => "J. R. R. Tolkien"
}

mongoClient.replace("books", query, replace) { |res_err,res|

  if (res_err == nil)

    puts "Book replaced !"

  else

    res_err.print_stack_trace()

  end

}


----

=== Bulk operations

To execute multiple insert, update, replace, or delete operations at once, use `link:../../yardoc/VertxMongo/MongoClient.html#bulk_write-instance_method[bulkWrite]`.

You can pass a list of `link:../dataobjects.html#BulkOperation[BulkOperations]`, with each working similiar to the matching single operations.
You can pass as many operations, even of the same type, as you wish.

To specify if the bulk operation should be executed in order, and with what write option, use `link:../../yardoc/VertxMongo/MongoClient.html#bulk_write_with_options-instance_method[bulkWriteWithOptions]`
and pass an instance of `link:../dataobjects.html#BulkWriteOptions[BulkWriteOptions]`.
For more explanation what ordered means, see https://docs.mongodb.com/manual/reference/method/db.collection.bulkWrite/#execution-of-operations

=== Finding documents

To find documents you use `link:../../yardoc/VertxMongo/MongoClient.html#find-instance_method[find]`.

The `query` parameter is used to match the documents in the collection.

Here's a simple example with an empty query that will match all books:

[source,ruby]
----
require 'json'

# empty query = match any
query = {
}

mongoClient.find("books", query) { |res_err,res|

  if (res_err == nil)

    res.each do |json|

      puts JSON.generate(json)

    end

  else

    res_err.print_stack_trace()

  end

}


----

Here's another example that will match all books by Tolkien:

[source,ruby]
----
require 'json'

# will match all Tolkien books
query = {
  'author' => "J. R. R. Tolkien"
}

mongoClient.find("books", query) { |res_err,res|

  if (res_err == nil)

    res.each do |json|

      puts JSON.generate(json)

    end

  else

    res_err.print_stack_trace()

  end

}


----

The matching documents are returned as a list of json objects in the result handler.

To specify things like what fields to return, how many results to return, etc use `link:../../yardoc/VertxMongo/MongoClient.html#find_with_options-instance_method[findWithOptions]`
and pass in the an instance of `link:../dataobjects.html#FindOptions[FindOptions]`.

This has the following fields:

`fields`:: The fields to return in the results. Defaults to `null`, meaning all fields will be returned
`sort`:: The fields to sort by. Defaults to `null`.
`limit`:: The limit of the number of results to return. Default to `-1`, meaning all results will be returned.
`skip`:: The number of documents to skip before returning the results. Defaults to `0`.

----
require 'json'

# will match all Tolkien books
query = {
  'author' => "J. R. R. Tolkien"
}

mongoClient.find_batch("book", query) { |res_err,res|

  if (res_err == nil)

    if (res == nil)

      puts "End of research"

    else

      puts "Found doc: #{JSON.generate(res)}"

    end

  else

    res_err.print_stack_trace()

  end
}


----

The matching documents are returned unitary in the result handler.

=== Finding a single document

To find a single document you use `link:../../yardoc/VertxMongo/MongoClient.html#find_one-instance_method[findOne]`.

This works just like `link:../../yardoc/VertxMongo/MongoClient.html#find-instance_method[find]` but it returns just the first matching document.

=== Removing documents

To remove documents use `link:../../yardoc/VertxMongo/MongoClient.html#remove_documents-instance_method[removeDocuments]`.

The `query` parameter is used to match the documents in the collection to determine which ones to remove.

Here's an example of removing all Tolkien books:

[source,ruby]
----

query = {
  'author' => "J. R. R. Tolkien"
}

mongoClient.remove("books", query) { |res_err,res|

  if (res_err == nil)

    puts "Never much liked Tolkien stuff!"

  else

    res_err.print_stack_trace()

  end
}


----

=== Removing a single document

To remove a single document you use `link:../../yardoc/VertxMongo/MongoClient.html#remove_document-instance_method[removeDocument]`.

This works just like `link:../../yardoc/VertxMongo/MongoClient.html#remove_documents-instance_method[removeDocuments]` but it removes just the first matching document.

=== Counting documents

To count documents use `link:../../yardoc/VertxMongo/MongoClient.html#count-instance_method[count]`.

Here's an example that counts the number of Tolkien books. The number is passed to the result handler.

[source,ruby]
----

query = {
  'author' => "J. R. R. Tolkien"
}

mongoClient.count("books", query) { |res_err,res|

  if (res_err == nil)

    num = res

  else

    res_err.print_stack_trace()

  end
}


----

=== Managing MongoDB collections

All MongoDB documents are stored in collections.

To get a list of all collections you can use `link:../../yardoc/VertxMongo/MongoClient.html#get_collections-instance_method[getCollections]`

[source,ruby]
----

mongoClient.get_collections() { |res_err,res|

  if (res_err == nil)

    collections = res

  else

    res_err.print_stack_trace()

  end
}


----

To create a new collection you can use `link:../../yardoc/VertxMongo/MongoClient.html#create_collection-instance_method[createCollection]`

[source,ruby]
----

mongoClient.create_collection("mynewcollectionr") { |res_err,res|

  if (res_err == nil)

    # Created ok!

  else

    res_err.print_stack_trace()

  end
}


----

To drop a collection you can use `link:../../yardoc/VertxMongo/MongoClient.html#drop_collection-instance_method[dropCollection]`

NOTE: Dropping a collection will delete all documents within it!

[source,ruby]
----

mongoClient.drop_collection("mynewcollectionr") { |res_err,res|

  if (res_err == nil)

    # Dropped ok!

  else

    res_err.print_stack_trace()

  end
}


----


=== Running other MongoDB commands

You can run arbitrary MongoDB commands with `link:../../yardoc/VertxMongo/MongoClient.html#run_command-instance_method[runCommand]`.

Commands can be used to run more advanced mongoDB features, such as using MapReduce.
For more information see the mongo docs for supported http://docs.mongodb.org/manual/reference/command[Commands].

Here's an example of running an aggregate command. Note that the command name must be specified as a parameter
and also be contained in the JSON that represents the command. This is because JSON is not ordered but BSON is
ordered and MongoDB expects the first BSON entry to be the name of the command. In order for us to know which
of the entries in the JSON is the command name it must be specified as a parameter.

[source,ruby]
----

command = {
  'aggregate' => "collection_name",
  'pipeline' => [
  ]
}

mongoClient.run_command("aggregate", command) { |res_err,res|
  if (res_err == nil)
    resArr = res['result']
    # etc
  else
    res_err.print_stack_trace()
  end
}


----

=== MongoDB Extended JSON support

For now, only date, oid and binary types are supported (cf http://docs.mongodb.org/manual/reference/mongodb-extended-json )

Here's an example of inserting a document with a date field

[source,ruby]
----

document = {
  'title' => "The Hobbit",
  'publicationDate' => {
    '$date' => "1937-09-21T00:00:00+00:00"
  }
}

mongoService.save("publishedBooks", document) { |res_err,res|

  if (res_err == nil)

    id = res

    mongoService.find_one("publishedBooks", {
      '_id' => id
    }, nil) { |res2_err,res2|
      if (res2_err == nil)

        puts "To retrieve ISO-8601 date : #{res2['publicationDate']['$date']}"

      else
        res2_err.print_stack_trace()
      end
    }

  else
    res_err.print_stack_trace()
  end

}


----

Here's an example (in Java) of inserting a document with a binary field and reading it back

[source,ruby]
----
byte[] binaryObject = new byte[40];

JsonObject document = new JsonObject()
        .put("name", "Alan Turing")
        .put("binaryStuff", new JsonObject().put("$binary", binaryObject));

mongoService.save("smartPeople", document, res -> {

  if (res.succeeded()) {

    String id = res.result();

    mongoService.findOne("smartPeople", new JsonObject().put("_id", id), null, res2 -> {
      if(res2.succeeded()) {

        byte[] reconstitutedBinaryObject = res2.result().getJsonObject("binaryStuff").getBinary("$binary");
        //This could now be de-serialized into an object in real life
      } else {
        res2.cause().printStackTrace();
      }
    });

  } else {
    res.cause().printStackTrace();
  }

});
----

Here's an example of inserting a base 64 encoded string, typing it as binary a binary field, and reading it back

[source,ruby]
----

#This could be a the byte contents of a pdf file, etc converted to base 64
base64EncodedString = "a2FpbHVhIGlzIHRoZSAjMSBiZWFjaCBpbiB0aGUgd29ybGQ="

document = {
  'name' => "Alan Turing",
  'binaryStuff' => {
    '$binary' => base64EncodedString
  }
}

mongoService.save("smartPeople", document) { |res_err,res|

  if (res_err == nil)

    id = res

    mongoService.find_one("smartPeople", {
      '_id' => id
    }, nil) { |res2_err,res2|
      if (res2_err == nil)

        reconstitutedBase64EncodedString = res2['binaryStuff']['$binary']
        #This could now converted back to bytes from the base 64 string
      else
        res2_err.print_stack_trace()
      end
    }

  else
    res_err.print_stack_trace()
  end

}


----
Here's an example of inserting an object ID and reading it back

[source,ruby]
----

individualId = Java::OrgBsonTypes::ObjectId.new().to_hex_string()

document = {
  'name' => "Stephen Hawking",
  'individualId' => {
    '$oid' => individualId
  }
}

mongoService.save("smartPeople", document) { |res_err,res|

  if (res_err == nil)

    id = res

    mongoService.find_one("smartPeople", {
      '_id' => id
    }, nil) { |res2_err,res2|
      if (res2_err == nil)
        reconstitutedIndividualId = res2['individualId']['$oid']
      else
        res2_err.print_stack_trace()
      end
    }

  else
    res_err.print_stack_trace()
  end

}


----
Here's an example of getting distinct value

[source,ruby]
----
document = {
  'title' => "The Hobbit"
}

mongoClient.save("books", document) { |res_err,res|

  if (res_err == nil)

    mongoClient.distinct("books", "title", Java::JavaLang::String::class.get_name()) { |res2_err,res2|
      puts "Title is : #{res2[0]}"
    }

  else
    res_err.print_stack_trace()
  end

}

----
Here's an example of getting distinct value in batch mode

[source,ruby]
----
document = {
  'title' => "The Hobbit"
}

mongoClient.save("books", document) { |res_err,res|

  if (res_err == nil)

    mongoClient.distinct_batch("books", "title", Java::JavaLang::String::class.get_name()) { |res2_err,res2|
      puts "Title is : #{res2['title']}"
    }

  else
    res_err.print_stack_trace()
  end

}

----

== Storing/Retrieving files and binary data

The client can store and retrieve files and binary data using MongoDB GridFS. The
`link:../../yardoc/VertxMongo/MongoGridFsClient.html[MongoGridFsClient]` can be used to upload or download files
to GridFS.

If you prefer to interact with GridFS using streams, the `link:../../yardoc/VertxMongo/MongoGridFsStreamClient.html[MongoGridFsStreamClient]`
can be used. This will allow you to upload from any implementation of `link:../../yardoc/Vertx/ReadStream.html[ReadStream]` and
download to any implementation of `link:../../yardoc/Vertx/WriteStream.html[WriteStream]`.

=== Get the MongoGridFsClient to interact with GridFS.

The `link:../../yardoc/VertxMongo/MongoGridFsClient.html[MongoGridFsClient]` is created by calling
`link:../../yardoc/VertxMongo/MongoClient.html#create_grid_fs_bucket_service-instance_method[createGridFsBucketService]` and providing a bucket name. In GridFS, the bucket name
ends up being a collection that contains references to all of the objects that are stored.
You can segregate objects into distinct buckets by providing a unique name.

This has the following fields:

`bucketName` : The name of the bucket to create

Here's an example of getting a `link:../../yardoc/VertxMongo/MongoGridFsClient.html[MongoGridFsClient]` with the a custom bucket
name

[source,ruby]
----
mongoClient.create_grid_fs_bucket_service("bakeke") { |res_err,res|
  if (res_err == nil)
    #Interact with the GridFS client...
    client = res
  else
    res_err.print_stack_trace()
  end
}

----

GridFS uses a default bucket named "fs". If you prefer to get the default bucket instead of naming your own,
call `link:../../yardoc/VertxMongo/MongoClient.html#create_default_grid_fs_bucket_service-instance_method[createDefaultGridFsBucketService]`

Here's an example of getting a `link:../../yardoc/VertxMongo/MongoGridFsClient.html[MongoGridFsClient]` with the default bucket name.

[source,ruby]
----
mongoClient.create_default_grid_fs_bucket_service() { |res_err,res|
  if (res_err == nil)
    #Interact with the GridFS client...
    client = res
  else
    res_err.print_stack_trace()
  end
}


----

=== Drop an entire file bucket from GridFS.

An entire file bucket along with all of its contents can be dropped with `link:../../yardoc/VertxMongo/MongoGridFsClient.html#drop-instance_method[drop]`. It will
drop the bucket that was specified when the MongoGridFsClient was created.

Here is an example of dropping a file bucket.

[source,ruby]
----
gridFsClient.drop() { |res_err,res|
  if (res_err == nil)
    #The file bucket is dropped and all files in it, erased
  else
    res_err.print_stack_trace()
  end
}

----

=== Find all file IDs in a GridFS bucket.

A list of all of the file IDs in a bucket can be found with `link:../../yardoc/VertxMongo/MongoGridFsClient.html#find_all_ids-instance_method[findAllIds]`.
The files can be downloaded by ID using `link:../../yardoc/VertxMongo/MongoGridFsClient.html#download_file_by_id-instance_method[downloadFileByID]`.

Here is an example of retrieving the list of file IDs.

[source,ruby]
----
gridFsClient.find_all_ids() { |res_err,res|
  if (res_err == nil)
    ids = res
  else
    res_err.print_stack_trace()
  end
}

----

=== Find file IDs in a GridFS bucket matching a query.

A query can be specified to match files in the GridFS bucket. `link:../../yardoc/VertxMongo/MongoGridFsClient.html#find_ids-instance_method[findIds]`
will return a list of file IDs that match the query.

This has the following fields:

`query` : The is a json object that can match any of the file's metadata using standard MongoDB query operators. An empty
json object will match all documents. You can query on attributes of the GridFS files collection as described
in the GridFS manual. https://docs.mongodb.com/manual/core/gridfs/#the-files-collection

The files can be downloaded by ID using `link:../../yardoc/VertxMongo/MongoGridFsClient.html#download_file_by_id-instance_method[downloadFileByID]`.

Here is an example of retrieving the list of file IDs based on a metadata query.

[source,ruby]
----
query = {
  'metadata.nick_name' => "Puhi the eel"
}
gridFsClient.find_ids(query) { |res_err,res|
  if (res_err == nil)
    ids = res
  else
    res_err.print_stack_trace()
  end
}

----

=== Delete a file in GridFS based on its ID.

A file previously stored in GridFS can be deleted with `link:../../yardoc/VertxMongo/MongoGridFsClient.html#delete-instance_method[delete]` by providing
the ID of the file. The file IDs can be retrieved with a query using `link:../../yardoc/VertxMongo/MongoGridFsClient.html#find_ids-instance_method[findIds]`.

This has the following fields:
`id` : The ID generated by GridFS when the file was stored

Here is an example of deleting a file by ID.

[source,ruby]
----
id = "56660b074cedfd000570839c"
gridFsClient.delete(id) { |res|
  if (res.succeeded?())
    #File deleted
  else
    #Something went wrong
    res.cause().print_stack_trace()
  end
}

----

=== Upload a file in GridFS

A file can be stored by name with `link:../../yardoc/VertxMongo/MongoGridFsClient.html#upload_file-instance_method[uploadFile]`. When it
succeeds, the ID generated by GridFS will be returned. This ID can be used to retrieve the file later.

This has the following fields:

`fileName` : this is name used to save the file in GridFS

[source,ruby]
----
gridFsClient.upload_file("file.name") { |res_err,res|
  if (res_err == nil)
    id = res
    #The ID of the stored object in Grid FS
  else
    res_err.print_stack_trace()
  end
}

----

=== Upload a file in GridFS with options.

A file can be stored with additional options with `link:../../yardoc/VertxMongo/MongoGridFsClient.html#upload_file_with_options-instance_method[uploadFileWithOptions]`
passing in an instance of `link:../dataobjects.html#UploadOptions[UploadOptions]`. When it
succeeds, the ID generated by GridFS will be returned.

This has the following fields:

`metadata` : this is a json object that includes any metadata that may be useful in a later search
`chunkSizeBytes` : GridFS will break up the file into chunks of this size

Here is an example of a file uploadByFileName that specifies the chunk size and metadata.

* [source,ruby]
----
metadata = {
}
metadata['nick_name'] = "Puhi the Eel"

options = {
}
options['chunkSizeBytes'] = 1024
options['metadata'] = metadata

gridFsClient.upload_file_with_options("file.name", options) { |res_err,res|
  if (res_err == nil)
    id = res
    #The ID of the stored object in Grid FS
  else
    res_err.print_stack_trace()
  end
}

----

=== Download a file previously stored in GridFS

A file can be downloaded by its original name with `link:../../yardoc/VertxMongo/MongoGridFsClient.html#download_file-instance_method[downloadFile]`.
When the download is complete, the result handler will return the length of the download as a Long.

This has the following fields:

`fileName`:: the name of the file that was previously stored

Here is an example of downloading a file using the name that it was stored with in GridFS.

* [source,ruby]
----
gridFsClient.download_file("file.name") { |res_err,res|
  if (res_err == nil)
    fileLength = res
    #The length of the file stored in fileName
  else
    res_err.print_stack_trace()
  end
}

----

=== Download a file previously stored in GridFS given its ID

A file can be downloaded to a given file name by its ID with `link:../../yardoc/VertxMongo/MongoGridFsClient.html#download_file_by_id-instance_method[downloadFileByID]`.
When the download succeeds, the result handler will return the length of the download as a Long.

This has the following fields:

`id` : The ID generated by GridFS when the file was stored

Here is an example of downloading a file using the ID that it was given when stored in GridFS.

* [source,ruby]
----
id = "56660b074cedfd000570839c"
filename = "puhi.fil"
gridFsClient.download_file_by_id(id, filename) { |res_err,res|
  if (res_err == nil)
    fileLength = res
    #The length of the file stored in fileName
  else
    res_err.print_stack_trace()
  end
}

----

=== Download a file from GridFS to a new name

A file can be resolved using its original name and then downloaded to a new name
with `link:../../yardoc/VertxMongo/MongoGridFsClient.html#download_file_as-instance_method[downloadFileAs]`.
When the download succeeds, the result handler will return the length of the download as a Long.

This has the following fields:

`fileName` : the name of the file that was previously stored
`newFileName` : the new name for which the file will be stored

* [source,ruby]
----
gridFsClient.download_file_as("file.name", "new_file.name") { |res_err,res|
  if (res_err == nil)
    fileLength = res
    #The length of the file stored in fileName
  else
    res_err.print_stack_trace()
  end
}

----

==== Uploading and Downloading to GridFS using Streams

The `link:../../yardoc/VertxMongo/MongoGridFsStreamClient.html[MongoGridFsStreamClient]` is used to interact with GridFS using streams.

To retrieve this client use `link:../../yardoc/VertxMongo/MongoGridFsClient.html#get_grid_fs_stream_client-instance_method[getGridFsStreamClient]`

Here is an example of retrieving the stream client:

* [source,ruby]
----
streamClient = gridFsClient.get_grid_fs_stream_client()

----

=== Upload a Stream to GridFS

Streams can be uploaded to GridFS using `link:../../yardoc/VertxMongo/MongoGridFsStreamClient.html#upload_by_file_name-instance_method[uploadByFileName]`.
Once the stream is uploaded, the result handler will be called with the ID generated by GridFS.

This has the following fields:

`stream` : the `link:../../yardoc/Vertx/ReadStream.html[ReadStream]` to upload
`fileName` : the name for which the stream will be stored

Here is an example of uploading a file stream to GridFS:

* [source,ruby]
----
gridFsStreamClient.upload_by_file_name(asyncFile, "kanaloa") { |stringAsyncResult_err,stringAsyncResult|
  id = stringAsyncResult
}

----

=== Upload a Stream to GridFS with Options

Streams can be uploaded to GridFS using `link:../../yardoc/VertxMongo/MongoGridFsStreamClient.html#upload_by_file_name_with_options-instance_method[uploadByFileNameWithOptions]`
passing in an instance of `link:../dataobjects.html#UploadOptions[UploadOptions]`.
Once the stream is uploaded, the result handler will be called with the ID generated by GridFS.

This has the following fields:

`stream` : the `link:../../yardoc/Vertx/ReadStream.html[ReadStream]` to upload
`fileName` : the name for which the stream will be stored
`options' : the UploadOptions

`link:../dataobjects.html#UploadOptions[UploadOptions]` has the following fields:

`metadata` : this is a json object that includes any metadata that may be useful in a later search
`chunkSizeBytes` : GridFS will break up the file into chunks of this size

Here is an example of uploading a file stream with options to GridFS:

* [source,ruby]
----
options = {
}
options['chunkSizeBytes'] = 2048
options['metadata'] = {
  'catagory' => "Polynesian gods"
}
gridFsStreamClient.upload_by_file_name_with_options(asyncFile, "kanaloa", options) { |stringAsyncResult_err,stringAsyncResult|
  id = stringAsyncResult
}


----

=== Download a Stream from GridFS using File Name

Streams can be downloaded from GridFS using a file name with `link:../../yardoc/VertxMongo/MongoGridFsStreamClient.html#download_by_file_name-instance_method[downloadByFileName]`.
Once the stream is downloaded a result handler will be called with the length of the stream as a Long.

This has the following fields:

`stream` : the `link:../../yardoc/Vertx/WriteStream.html[WriteStream]` to download to
`fileName` : the name of the file that will be downloaded to the stream.

Here is an example of downloading a file to a stream:

* [source,ruby]
----
gridFsStreamClient.download_by_file_name(asyncFile, "kamapuaa.fil") { |longAsyncResult_err,longAsyncResult|
  length = longAsyncResult
}

----

=== Download a Stream with Options from GridFS using File Name

Streams can be downloaded from GridFS using a file name and download options with
`link:../../yardoc/VertxMongo/MongoGridFsStreamClient.html#download_by_file_name_with_options-instance_method[downloadByFileNameWithOptions]` passing in an instance of `link:../dataobjects.html#DownloadOptions[DownloadOptions]`.
Once the stream is downloaded a result handler will be called with the length of the stream as a Long.

This has the following fields:

`stream` : the `link:../../yardoc/Vertx/WriteStream.html[WriteStream]` to download to
`fileName` : the name of the file that will be downloaded to the stream
`options` : an instance of `link:../dataobjects.html#DownloadOptions[DownloadOptions]`

DownloadOptions has the following field:

`revision` : the revision of the file to download

Here is an example of downloading a file to a stream with options:

* [source,ruby]
----
options = {
}
options['revision'] = 0
gridFsStreamClient.download_by_file_name_with_options(asyncFile, "kamapuaa.fil", options) { |longAsyncResult_err,longAsyncResult|
  length = longAsyncResult
}

----

=== Download a Stream from GridFS using ID

Streams can be downloaded using the ID generated by GridFS with `link:../../yardoc/VertxMongo/MongoGridFsStreamClient.html#download_by_id-instance_method[downloadById]`.
Once the stream is downloaded a result handler will be called with the length of the stream as a Long.

This has the following fields:

`stream` : the `link:../../yardoc/Vertx/WriteStream.html[WriteStream]` to download to
`id` : the string represendation of the ID generated by GridFS

Here is an example of downloading a file to a stream using the object's ID:

* [source,ruby]
----
id = "58f61bf84cedfd000661af06"
gridFsStreamClient.download_by_id(asyncFile, id) { |longAsyncResult_err,longAsyncResult|
  length = longAsyncResult
}

----

== Configuring the client

The client is configured with a json object.

The following configuration is supported by the mongo client:


`db_name`:: Name of the database in the mongoDB instance to use. Defaults to `default_db`
`useObjectId`:: Toggle this option to support persisting and retrieving ObjectId's as strings. If `true`, hex-strings will
be saved as native Mongodb ObjectId types in the document collection. This will allow the sorting of documents based on creation
time. You can also derive the creation time from the hex-string using ObjectId::getDate(). Set to `false` for other types of your choosing.
If set to false, or left to default, hex strings will be generated as the document _id if the _id is omitted from the document.
Defaults to `false`.

The mongo client tries to support most options that are allowed by the driver. There are two ways to configure mongo
for use by the driver, either by a connection string or by separate configuration options.

NOTE: If the connection string is used the mongo client will ignore any driver configuration options.

`connection_string`:: The connection string the driver uses to create the client. E.g. `mongodb://localhost:27017`.
For more information on the format of the connection string please consult the driver documentation.

*Specific driver configuration options*

----
{
  // Single Cluster Settings
  "host" : "127.0.0.1", // string
  "port" : 27017,      // int

  // Multiple Cluster Settings
  "hosts" : [
    {
      "host" : "cluster1", // string
      "port" : 27000       // int
    },
    {
      "host" : "cluster2", // string
      "port" : 28000       // int
    },
    ...
  ],
  "replicaSet" :  "foo",    // string
  "serverSelectionTimeoutMS" : 30000, // long

  // Connection Pool Settings
  "maxPoolSize" : 50,                // int
  "minPoolSize" : 25,                // int
  "maxIdleTimeMS" : 300000,          // long
  "maxLifeTimeMS" : 3600000,         // long
  "waitQueueMultiple"  : 10,         // int
  "waitQueueTimeoutMS" : 10000,      // long
  "maintenanceFrequencyMS" : 2000,   // long
  "maintenanceInitialDelayMS" : 500, // long

  // Credentials / Auth
  "username"   : "john",     // string
  "password"   : "passw0rd", // string
  "authSource" : "some.db"   // string
  // Auth mechanism
  "authMechanism"     : "GSSAPI",        // string
  "gssapiServiceName" : "myservicename", // string

  // Socket Settings
  "connectTimeoutMS" : 300000, // int
  "socketTimeoutMS"  : 100000, // int
  "sendBufferSize"    : 8192,  // int
  "receiveBufferSize" : 8192,  // int
  "keepAlive" : true           // boolean

  // Heartbeat socket settings
  "heartbeat.socket" : {
  "connectTimeoutMS" : 300000, // int
  "socketTimeoutMS"  : 100000, // int
  "sendBufferSize"    : 8192,  // int
  "receiveBufferSize" : 8192,  // int
  "keepAlive" : true           // boolean
  }

  // Server Settings
  "heartbeatFrequencyMS" :    1000 // long
  "minHeartbeatFrequencyMS" : 500 // long
}
----

*Driver option descriptions*

`host`:: The host the mongoDB instance is running. Defaults to `127.0.0.1`. This is ignored if `hosts` is specified
`port`:: The port the mongoDB instance is listening on. Defaults to `27017`. This is ignored if `hosts` is specified
`hosts`:: An array representing the hosts and ports to support a mongoDB cluster (sharding / replication)
`host`:: A host in the cluster
`port`:: The port a host in the cluster is listening on
`replicaSet`:: The name of the replica set, if the mongoDB instance is a member of a replica set
`serverSelectionTimeoutMS`:: The time in milliseconds that the mongo driver will wait to select a server for an operation before raising an error.
`maxPoolSize`:: The maximum number of connections in the connection pool. The default value is `100`
`minPoolSize`:: The minimum number of connections in the connection pool. The default value is `0`
`maxIdleTimeMS`:: The maximum idle time of a pooled connection. The default value is `0` which means there is no limit
`maxLifeTimeMS`:: The maximum time a pooled connection can live for. The default value is `0` which means there is no limit
`waitQueueMultiple`:: The maximum number of waiters for a connection to become available from the pool. Default value is `500`
`waitQueueTimeoutMS`:: The maximum time that a thread may wait for a connection to become available. Default value is `120000` (2 minutes)
`maintenanceFrequencyMS`:: The time period between runs of the maintenance job. Default is `0`.
`maintenanceInitialDelayMS`:: The period of time to wait before running the first maintenance job on the connection pool. Default is `0`.
`username`:: The username to authenticate. Default is `null` (meaning no authentication required)
`password`:: The password to use to authenticate.
`authSource`:: The database name associated with the user's credentials. Default value is the `db_name` value.
`authMechanism`:: The authentication mechanism to use. See [Authentication](http://docs.mongodb.org/manual/core/authentication/) for more details.
`gssapiServiceName`:: The Kerberos service name if `GSSAPI` is specified as the `authMechanism`.
`connectTimeoutMS`:: The time in milliseconds to attempt a connection before timing out. Default is `10000` (10 seconds)
`socketTimeoutMS`:: The time in milliseconds to attempt a send or receive on a socket before the attempt times out. Default is `0` meaning there is no timeout
`sendBufferSize`:: Sets the send buffer size (SO_SNDBUF) for the socket. Default is `0`, meaning it will use the OS default for this option.
`receiveBufferSize`:: Sets the receive buffer size (SO_RCVBUF) for the socket. Default is `0`, meaning it will use the OS default for this option.
`keepAlive`:: Sets the keep alive (SO_KEEPALIVE) for the socket. Default is `false`
`heartbeat.socket`:: Configures the socket settings for the cluster monitor of the MongoDB java driver.
`heartbeatFrequencyMS`:: The frequency that the cluster monitor attempts to reach each server. Default is `5000` (5 seconds)
`minHeartbeatFrequencyMS`:: The minimum heartbeat frequency. The default value is `1000` (1 second)

NOTE: Most of the default values listed above use the default values of the MongoDB Java Driver.
Please consult the driver documentation for up to date information.